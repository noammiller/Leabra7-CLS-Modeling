{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noamm/anaconda3/envs/leabra7/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import torch\n",
    "torch.set_printoptions(precision = 1)\n",
    "\n",
    "import leabra7 as lb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ThetaTrough = lb.Phase(\"theta_trough\", \"minus\")\n",
    "ThetaPeak = lb.Phase(\"theta_peak\", \"minus\")\n",
    "ThetaPlus = lb.Phase(\"theta_plus\", \"plus\")\n",
    "TestPhase = lb.Phase(\"test\", \"minus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define Layer Specs\n",
    "\n",
    "# Generic Layer Spec\n",
    "layer_spec = lb.LayerSpec()\n",
    "\n",
    "# EC Layer Spec\n",
    "EC_layer_spec = lb.LayerSpec(\n",
    "    inhibition_type = \"kwta\",\n",
    "    kwta_pct = 0.25,\n",
    "    kwta_pt = 0.5,\n",
    ")\n",
    "\n",
    "# DG Layer Spec\n",
    "DG_layer_spec = lb.LayerSpec(\n",
    "    inhibition_type = \"kwta_avg\",\n",
    "    kwta_pct = 0.01,\n",
    "    kwta_pt = 0.9,\n",
    ")\n",
    "\n",
    "# CA3 Layer Spec\n",
    "CA3_layer_spec = lb.LayerSpec(\n",
    "    inhibition_type = \"kwta_avg\",\n",
    "    kwta_pct = 0.06,\n",
    "    kwta_pt = 0.7,\n",
    ")\n",
    "\n",
    "# CA1 Layer Spec\n",
    "CA1_layer_spec = lb.LayerSpec(\n",
    "    inhibition_type = \"kwta_avg\",\n",
    "    kwta_pct = 0.25,\n",
    "    kwta_pt = 0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define Projections Spec\n",
    "\n",
    "# Input -> EC_in\n",
    "Input_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    lrate = 0,\n",
    "    projn_type = \"one_to_one\",\n",
    "    minus_phase = lb.NonePhase,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# EC_in -> DG\n",
    "# EC_in -> CA3\n",
    "EC_in_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    lrate = 0.2,\n",
    "    sparsity = 0.25,\n",
    "    minus_phase = lb.NonePhase,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# DG -> CA3 (Mossy Fiber)\n",
    "DG_CA3_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.89, high=0.91),\n",
    "    wt_scale_rel = 8.0,\n",
    "    sparsity = 0.05,\n",
    "    lrate = 0,\n",
    "    minus_phase = lb.NonePhase,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# CA3 -> CA3\n",
    "CA3_CA3_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    lrate = 0.2,\n",
    "    minus_phase = lb.NonePhase,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# CA3 -> CA1 (Schaffer)\n",
    "CA3_CA1_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    lrate = 0.05,\n",
    "    minus_phase = ThetaPeak,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# EC_in -> CA1 Projection Spec\n",
    "EC_in_CA1_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    wt_scale_abs = 3.0,\n",
    "    lrate = 0.02,\n",
    "    minus_phase = ThetaTrough,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# EC_out <--> CA1 Projection Spec\n",
    "EC_out_CA1_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.25, high=0.75),\n",
    "    lrate = 0.02,\n",
    "    minus_phase = ThetaTrough,\n",
    "    plus_phase = ThetaPlus,\n",
    ")\n",
    "\n",
    "# EC_out -> EC_in Projection Spec\n",
    "EC_out_EC_in_projn_spec = lb.ProjnSpec(\n",
    "    dist=lb.Uniform(low=0.49, high=0.51),\n",
    "    lrate = 0,\n",
    "    wt_scale_abs = 2.0,\n",
    "    wt_scale_rel = 0.5,\n",
    "    projn_type = \"one_to_one\",\n",
    "    minus_phase = lb.NonePhase,\n",
    "    plus_phase = ThetaPlus,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_net() -> lb.Net:\n",
    "    # Create the Network\n",
    "    net = lb.Net()\n",
    "\n",
    "    ## Create Layers\n",
    "\n",
    "    # Create input and output layers\n",
    "    net.new_layer(\"Input\", 8, layer_spec)\n",
    "    net.new_layer(\"EC_in\", 8, EC_layer_spec)\n",
    "    net.new_layer(\"EC_out\", 8, EC_layer_spec)\n",
    "\n",
    "    # Create cortical layers\n",
    "    net.new_layer(\"CA1\", 100, CA1_layer_spec)\n",
    "    net.new_layer(\"CA3\", 80, CA3_layer_spec)\n",
    "\n",
    "    # Create hippocampus\n",
    "    net.new_layer(\"DG\", 400, DG_layer_spec)\n",
    "\n",
    "    ## Create Projections\n",
    "\n",
    "    # Input Feed\n",
    "    net.new_projn(\"Input: Input -> EC_in\", \"Input\", \"EC_in\", spec=Input_projn_spec)\n",
    "    net.new_projn(\"Loop: EC_out -> EC_in\", \"EC_out\", \"EC_in\", spec=EC_out_EC_in_projn_spec)\n",
    "\n",
    "    # Create MSP\n",
    "    net.new_projn(\"MSP: EC_in -> CA1\", \"EC_in\", \"CA1\", spec=EC_in_CA1_projn_spec)\n",
    "    net.new_projn(\"MSP: CA1 -> EC_out\", \"CA1\", \"EC_out\", spec=EC_out_CA1_projn_spec)\n",
    "    net.new_projn(\"MSP: EC_out -> CA1\", \"EC_out\", \"CA1\", spec=EC_out_CA1_projn_spec)\n",
    "\n",
    "    # Create TSP\n",
    "    net.new_projn(\"TSP: EC_in -> DG\", \"EC_in\", \"DG\", spec=EC_in_projn_spec)\n",
    "    net.new_projn(\"TSP: EC_in -> CA3\", \"EC_in\", \"CA3\", spec=EC_in_projn_spec)\n",
    "    net.new_projn(\"TSP: DG -> CA3\", \"DG\", \"CA3\", spec=DG_CA3_projn_spec)\n",
    "    net.new_projn(\"TSP: CA3 -> CA3\", \"CA3\", \"CA3\", spec=CA3_CA3_projn_spec)\n",
    "    net.new_projn(\"TSP: CA3 -> CA1\", \"CA3\", \"CA1\", spec=CA3_CA1_projn_spec)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to plot data for a certain attribute for each unit of layer\n",
    "def plot_by_unit(axes: List[matplotlib.axes.Axes], \n",
    "                 log: pd.DataFrame, attr: str, title: str, location: List) -> None:\n",
    "    for name, group in log.groupby(\"unit\"):\n",
    "        group.plot(x=\"time\", y=attr, ax=axes[location], \n",
    "                   title = title, label=\"unit \" + str(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_dict = dict()\n",
    "sequence_dict[0] = [1]\n",
    "sequence_dict[2] = [3]\n",
    "sequence_dict[4] = [5]\n",
    "sequence_dict[6] = [7]\n",
    "\n",
    "sequence_dict[1] = [2, 4, 6]\n",
    "sequence_dict[3] = [0, 4, 6]\n",
    "sequence_dict[5] = [0, 2, 6]\n",
    "sequence_dict[7] = [0, 2, 4]\n",
    "\n",
    "def seq_next(prev: int) -> int:\n",
    "    return random.choice(sequence_dict[prev])\n",
    "\n",
    "def tensorfy(old_num: int, new_num: int) -> torch.Tensor:\n",
    "    x = torch.FloatTensor(8).zero_()\n",
    "    if new_num != None:\n",
    "        x[new_num] = 1\n",
    "    if old_num != None:\n",
    "        x[old_num] = 0.9\n",
    "    return x\n",
    "\n",
    "def gen_train_seq_epoch(epoch_len) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "    old_seed = None\n",
    "    curr_seed = random.randint(0,7)\n",
    "    \n",
    "    inputs: List[torch.Tensor] = []\n",
    "    outputs: List[torch.Tensor] = []\n",
    "        \n",
    "    for _ in range(epoch_len):\n",
    "        inputs += [tensorfy(old_seed, curr_seed)]\n",
    "        \n",
    "        old_seed = curr_seed\n",
    "        \n",
    "        curr_seed = seq_next(old_seed)\n",
    "        outputs += [tensorfy(None, curr_seed)]\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "def gen_train_sep_epoch(epoch_len) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "    inputs: List[torch.Tensor] = []\n",
    "    outputs: List[torch.Tensor] = []\n",
    "        \n",
    "    for i in range(epoch_len):\n",
    "        curr_seed = random.choice([0, 2, 4, 6])\n",
    "        inputs += [tensorfy(None, curr_seed)]\n",
    "        next_seed = seq_next(curr_seed)\n",
    "        outputs += [tensorfy(None, next_seed)]\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "def gen_test() -> Tuple[List[torch.Tensor], List[torch.Tensor]]:    \n",
    "    inputs: List[torch.Tensor] = []\n",
    "    outputs: List[torch.Tensor] = []\n",
    "        \n",
    "    for curr_seed in range(8):\n",
    "        inputs += [tensorfy(None, curr_seed)] \n",
    "        if curr_seed in {0, 2, 4, 6}:\n",
    "            next_seed = seq_next(curr_seed)\n",
    "        else:\n",
    "            next_seed = None\n",
    "        outputs += [tensorfy(None, next_seed)]\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_snapshot(network: lb.Net) -> Dict[str, torch.Tensor]:\n",
    "    act_dict: Dict[str, torch.Tensor] = dict()\n",
    "        \n",
    "    for name, layer in network.layers.items():\n",
    "        act_dict[name] = layer.units.act\n",
    "        \n",
    "    return act_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(patterns: Dict[int, torch.Tensor]) -> torch.Tensor:\n",
    "    dim = len(patterns.keys())\n",
    "    corr_matrix = torch.FloatTensor(dim, dim).zero_()\n",
    "    \n",
    "    for i in range(dim):\n",
    "        for j in range(i, dim):\n",
    "            corr = float(pearsonr(patterns[i], patterns[j])[0])\n",
    "            if math.isnan(corr):\n",
    "                corr = 0.0\n",
    "            corr_matrix[i, j] = corr_matrix[j, i] = corr\n",
    "    \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_trial(network: lb.Net, input_pattern = torch.Tensor, output_pattern = torch.Tensor) -> None:\n",
    "    # Theta Trough\n",
    "    network.clamp_layer(\"Input\", input_pattern)\n",
    "    network.uninhibit_projns(\"MSP: EC_in -> CA1\")\n",
    "    network.inhibit_projns(\"TSP: CA3 -> CA1\", \"Loop: EC_out -> EC_in\")\n",
    "    network.phase_cycle(ThetaTrough, num_cycles = 20)\n",
    "    # Theta Peak\n",
    "    network.uninhibit_projns(\"TSP: CA3 -> CA1\")\n",
    "    network.inhibit_projns(\"MSP: EC_in -> CA1\", \"Loop: EC_out -> EC_in\")\n",
    "    network.phase_cycle(ThetaPeak, num_cycles = 20)\n",
    "    # Theta Plus\n",
    "    network.uninhibit_projns(\"MSP: EC_in -> CA1\", \"Loop: EC_out -> EC_in\")\n",
    "    network.inhibit_projns(\"TSP: CA3 -> CA1\")\n",
    "    network.clamp_layer(\"EC_out\", output_pattern)\n",
    "    network.phase_cycle(ThetaPlus, num_cycles = 60)\n",
    "    # Reset\n",
    "    network.uninhibit_projns(\"TSP: CA3 -> CA1\")\n",
    "    network.unclamp_layer(\"EC_in\", \"EC_out\")\n",
    "    network.end_trial()\n",
    "    network.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_trial(network: lb.Net, input_pattern = torch.Tensor, output_pattern = torch.Tensor) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor], bool, bool]:\n",
    "    # Initial Response\n",
    "    network.clamp_layer(\"Input\", input_pattern)\n",
    "    network.phase_cycle(TestPhase, num_cycles = 20)\n",
    "    \n",
    "    initial_response = net_snapshot(network)\n",
    "    print(initial_response[\"EC_out\"])\n",
    "    initial_guess = ((initial_response[\"EC_out\"] > 0.5) == output_pattern.byte()).all()\n",
    "    \n",
    "    # Final Response\n",
    "    network.phase_cycle(TestPhase, num_cycles = 60)\n",
    "    \n",
    "    final_response = net_snapshot(network)\n",
    "    final_guess = ((final_response[\"EC_out\"] > 0.5) == output_pattern.byte()).all()\n",
    "    \n",
    "    # Reset\n",
    "    network.end_trial()\n",
    "    \n",
    "    return initial_response, final_response, initial_guess, final_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(network: lb.Net, seq: bool, num_trial) -> None:\n",
    "    if seq:\n",
    "        epoch_input, epoch_output = gen_train_seq_epoch(num_trial)\n",
    "    else:\n",
    "        epoch_input, epoch_output = gen_train_sep_epoch(num_trial)\n",
    "        \n",
    "    for t in range(len(epoch_input)):\n",
    "        learn_trial(network, epoch_input[t], epoch_output[t])\n",
    "        \n",
    "    print(\"epoch done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(network: lb.Net) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor], float, float]:\n",
    "    epoch_input, epoch_output = gen_test()\n",
    "    \n",
    "    initial_correct = 0\n",
    "    final_correct = 0\n",
    "    \n",
    "    hidden_layers: Set[str] = {\"DG\", \"CA3\", \"CA1\"}\n",
    "    \n",
    "    initial_acts: Dict[str, Dict[int, torch.Tensor]] = {\"DG\": dict(), \"CA3\": dict(), \"CA1\": dict()}\n",
    "    final_acts: Dict[str, Dict[int, torch.Tensor]] = {\"DG\": dict(), \"CA3\": dict(), \"CA1\": dict()}\n",
    "    \n",
    "    for t in range(len(epoch_input)):\n",
    "        initial_response, final_response, initial_guess, final_guess = test_trial(network, epoch_input[t], epoch_output[t])\n",
    "        \n",
    "        print(initial_guess)\n",
    "        \n",
    "        for layer in hidden_layers:    \n",
    "            initial_acts[layer][t] = initial_response[layer]\n",
    "            final_acts[layer][t] = final_response[layer]\n",
    "        \n",
    "        initial_correct += initial_guess\n",
    "        final_correct += final_guess\n",
    "        \n",
    "    initial_matrix: Dict[str, torch.Tensor] = dict()\n",
    "    final_matrix: Dict[str, torch.Tensor] = dict()\n",
    "        \n",
    "    for layer in hidden_layers:\n",
    "        initial_matrix[layer] = pearson_correlation(initial_acts[layer])\n",
    "        final_matrix[layer] = pearson_correlation(final_acts[layer])\n",
    "        \n",
    "    initial_accuracy = float(initial_correct) / len(epoch_input)\n",
    "    final_accuracy = float(final_correct) / len(epoch_input)\n",
    "    \n",
    "    print(\"network done\")\n",
    "    \n",
    "    return initial_matrix, final_matrix, initial_accuracy, final_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(networks: List[lb.Net]) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor], float, float]:\n",
    "    \n",
    "    hidden_layers: Set[str] = {\"DG\", \"CA3\", \"CA1\"}\n",
    "    \n",
    "    im_sum: Dict[str, torch.Tensor] = dict()\n",
    "    fm_sum: Dict[str, torch.Tensor] = dict()\n",
    "    \n",
    "    for layer in hidden_layers:\n",
    "        im_sum[layer] = torch.FloatTensor(8, 8).zero_()\n",
    "        fm_sum[layer] = torch.FloatTensor(8, 8).zero_()\n",
    "    \n",
    "    ia_sum = 0\n",
    "    fa_sum = 0\n",
    "    \n",
    "    for _, net in enumerate(networks):\n",
    "#         print(net)\n",
    "        im, fm, ia, fa = test_epoch(net)\n",
    "        \n",
    "        for layer in hidden_layers:\n",
    "#             print(im[layer])\n",
    "            im_sum[layer] += im[layer]\n",
    "            fm_sum[layer] += fm[layer]\n",
    "            \n",
    "        ia_sum += ia\n",
    "        fa_sum += fa\n",
    "    \n",
    "    num_net = len(networks)\n",
    "    \n",
    "    print(ia_sum)\n",
    "    \n",
    "    ia_sum /= num_net\n",
    "    fa_sum /= num_net\n",
    "    \n",
    "    for layer in hidden_layers:\n",
    "#         print(im_sum[layer])\n",
    "        im_sum[layer] /= num_net\n",
    "        fm_sum[layer] /= num_net\n",
    "        \n",
    "    return im_sum, fm_sum, ia_sum, fa_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "1\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "2\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "3\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "4\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "5\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "6\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "7\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "8\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n",
      "9\n",
      "separate\n",
      "epoch done\n",
      "\n",
      "sequence\n",
      "epoch done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_networks = 1\n",
    "num_trials = 1\n",
    "nets_sep = [gen_net() for i in range(num_networks)]\n",
    "nets_seq = [gen_net() for i in range(num_networks)]\n",
    "\n",
    "# process_seq = [mp.Process(target = train_epoch, args = (net, True, 10, 100)) for net in nets_seq]\n",
    "# process_sep = [mp.Process(target = train_epoch, args = (net, False, 10, 100)) for net in nets_sep]\n",
    "\n",
    "for e in range(10):\n",
    "    print(e)\n",
    "    \n",
    "    process_sep = [mp.Process(target = train_epoch, args = (net, False, num_trials)) for net in nets_sep]\n",
    "    process_seq = [mp.Process(target = train_epoch, args = (net, True, num_trials)) for net in nets_seq]\n",
    "    \n",
    "    print(\"separate\")\n",
    "    for p in process_sep:\n",
    "        p.start()\n",
    "\n",
    "    for p in process_sep:\n",
    "        p.join()\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"sequence\")\n",
    "    for p in process_seq:\n",
    "        p.start()\n",
    "\n",
    "    for p in process_seq:\n",
    "        p.join()\n",
    "        \n",
    "    print()\n",
    "    print()\n",
    "\n",
    "# train(nets_seq, seq = True, num_epoch = 10, num_trial = 100)\n",
    "# train(nets_sep, seq = False, num_epoch = 10, num_trial = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8e-03, 4.8e-02, 9.5e-06, 1.7e-05, 1.2e-02, 8.3e-03, 3.7e-02, 1.5e-07])\n",
      "tensor(0, dtype=torch.uint8)\n",
      "tensor([1.4e-05, 3.2e-02, 1.1e-03, 1.9e-04, 7.5e-01, 6.8e-04, 2.5e-05, 2.6e-06])\n",
      "tensor(0, dtype=torch.uint8)\n",
      "tensor([4.2e-04, 3.0e-04, 1.5e-02, 6.5e-01, 1.7e-05, 6.4e-04, 2.5e-04, 5.0e-03])\n",
      "tensor(1, dtype=torch.uint8)\n",
      "tensor([7.5e-03, 5.0e-02, 4.1e-04, 4.4e-06, 1.0e-05, 7.0e-05, 3.4e-05, 2.0e-02])\n",
      "tensor(1, dtype=torch.uint8)\n",
      "tensor([2.9e-03, 1.1e-04, 3.3e-02, 5.5e-04, 1.6e-01, 1.7e-02, 8.1e-08, 1.2e-06])\n",
      "tensor(0, dtype=torch.uint8)\n",
      "tensor([6.7e-04, 2.2e-02, 1.8e-04, 1.2e-02, 7.6e-05, 6.1e-05, 1.4e-07, 2.6e-01])\n",
      "tensor(1, dtype=torch.uint8)\n",
      "tensor([6.4e-04, 5.0e-02, 6.8e-04, 8.0e-09, 2.7e-04, 1.4e-04, 9.0e-06, 3.1e-01])\n",
      "tensor(0, dtype=torch.uint8)\n",
      "tensor([4.5e-03, 4.1e-03, 3.1e-02, 8.1e-07, 1.0e-01, 2.5e-02, 4.3e-03, 3.0e-06])\n",
      "tensor(1, dtype=torch.uint8)\n",
      "network done\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# _, _, x, y = test(nets_seq)\n",
    "pickle.dump(test(nets_seq), open(\"/tigress/noamm/nets_seq.pkl\", \"wb\"))\n",
    "pickle.dump(test(nets_sep), open(\"/tigress/noamm/nets_sep.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python leabra7",
   "language": "python",
   "name": "leabra7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
